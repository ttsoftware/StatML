\documentclass[12pt, a4paper]{article}
\usepackage{array}
\usepackage{longtable}
\usepackage[table]{xcolor}
\usepackage{hyperref}
\usepackage{float}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage[margin=1 in]{geometry}
\usepackage{color}
\usepackage{caption}
\usepackage{pdflscape}
\usepackage{fancyhdr}

\title{Assignment 1: Foundations\\Statistical Methods for Machine Learning}
\author{Troels Thomsen - qvw203\\Rasmus Haarslev - nkh877\\Allan Martin Nielsen - jcl187}

\setlength\parindent{0pt}		% noindent through whole document
\usepackage[parfill]{parskip}	% extra linebreak on new paragraph

\begin{document}
\pagestyle{empty}
\maketitle
\newpage

\pagestyle{fancy}
\fancyhead[LO,LE]{qvw203 - nkh877 - jcl187}
\fancyhead[RO, RE]{Assignment 1}

\section{I.2.1}
\begin{itemize}
\item plot for $(\mu, \sigma) = {(-1, 1), (1, 2), (2, 3)}$
\begin{figure}[!h]
    \centering
    \includegraphics[width=0.9\textwidth]{1.png}
    \caption{$(\mu, \sigma)$}
    \label{fig:awesome_image}
\end{figure}
\end{itemize}
\section{I.2.2}
\begin{itemize}
\item Plot your dataset

\includegraphics[width=0.9\textwidth]{2.png}
\end{itemize}
\section{I.2.3}
\begin{itemize}
\item Estimate the maximum likelihood sample mean of the data set
\item Plot the sample mean and distribution mean as points in a 2-dimensional plot
together with the data points.

\includegraphics[width=\textwidth]{5.png}

\item Quantify how much the sample mean deviate from
the distribution mean.
\item Why do you see a deviation from the distribution mean (concis diskussion)
\end{itemize}



\section{I.2.4}
\begin{itemize}
\item \textit{Plot the scaled and translated eigenvectors
$\mu + \sqrt{\lambda_i} * e_i$}

\includegraphics[width=\textwidth]{6.png}

\item \textit{Discuss how to interpret the
eigenvectors and eigenvalues of $\sum _{ML} $
on top of the sampled data from Question I.2.2}

The length of the scaled and translated eigenvectors represent the spread from the sample mean in orthogonal directions. 

\item \textit{Plot the samples from the rotated distributions in different colors in a combined plot.}

\includegraphics[width=\textwidth]{7.png}

\item Explain what you see.
\item \textit{Can you find an angle $\phi$ such that the main direction of the data sampled from
the Gaussian distribution $\mathcal{N}(y|\mu, \sum \phi )$ points along the x axis?}\\\\
To find this angle we use the information, that when it is rotated this way, the eigenvector describing the width of the spread, will be orthogonal on the x-axis and therefore directly vertical (its x-direction is zero and its y-direction is exactly its length).\\
Knowing this, we can isolate $\phi$ in the equation for rotating a vector. It will still have the same length as before, so we can set up the following equation, where \textbf{a} is the vector to be rotated and \textbf{R} is the rotation-matrix:
\begin{equation*}
\left( \begin{array}{c}
0 \\
|\textbf{a}| \end{array} \right)
=
\textbf{R}\textbf{a}
\end{equation*}
\begin{equation*}
\left( \begin{array}{c}
0 \\
\sqrt{x_a^2+y_a^2} 
\end{array} \right)
=
\left( \begin{array}{cc}
\cos \phi & -\sin \phi \\
\sin \phi & \cos \phi \end{array} \right)
\left( \begin{array}{c}
x_a \\
y_a \end{array} \right)
\end{equation*} 
Now we can isolate $\phi$ and find a general equation for calculating this angle to align the length of the spread, with the x-axis:
\begin{equation*}
\phi = cos^{-1}\left(\dfrac{y_a}{\sqrt{x_a^2+y_a^2}}\right)
\end{equation*} 

\includegraphics[width=\textwidth]{8.png}

\end{itemize}

\section{I.3.1}

Running the algorithms for various k's, we get the following accuracies:

\begin{itemize}
\item[-] k = 1; 0.815789473684\%
\item[-] k = 3; 0.710526315789\% 
\item[-] k = 5; 0.736842105263\%
\end{itemize}

As such, k = 1 is clearly the best k for this training- and test set.

\section{I.3.2}
\begin{itemize}
\item \textit{a short description of how you proceeded (e.g., did the
cross-validation)}
\item number of neighbors as suggested by hyperparameter selection;
\item training and test error of k best -NN
\end{itemize}

Initially the algorithm creates $S$ pairs of test and training sets .

Then it iterates through a each $k$ and calculates the accuracy for each test/training pair, by giving the data-points from the test set, to the nearest\_neightbour-function, that is trained with the corresponding training set.

If the accuracy is greater then the previous $best\_k$, then we set it to this.

The program then returns the $best\_k$.\\\\
When run, the program suggests $best\_k = 3$.\\\\
This yields and accuracy $0.710526315789$ for the test set, using $best\_k = 3$. This is the same as having an classification error equal to 1 with the accuracy subtracted.


\section{I.3.3}
\begin{itemize}
\item Mean and variance of the training data
\item mean and variance of the transformed test data
\item Now repeat exercise I.3.2 with the normalized data instead of the raw data.
Perform cross-validation and report the training and test error using the value
of k found by the cross-validation procedure.
\item Can you explain the differences
compared to the results achieved using the raw (not normalized) data?
\end{itemize}
\end{document}

