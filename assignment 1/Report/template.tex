\documentclass[12pt, a4paper]{article}
\usepackage{array}
\usepackage{tabu}
\usepackage{longtable}
\usepackage[table]{xcolor}
\usepackage{hyperref}
\usepackage{float}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage[margin=1 in]{geometry}
\usepackage{color}
\usepackage{caption}
\usepackage{subfigure}
\usepackage{fancyhdr}
\usepackage{pdflscape}


\title{Assignment 1: Foundations\\Statistical Methods for Machine Learning}
\author{Troels Thomsen - qvw203\\Rasmus Haarslev - nkh877\\Allan Martin Nielsen - }

\setlength\parindent{0pt}		% noindent through whole document
\usepackage[parfill]{parskip}	% extra linebreak on new paragraph

\begin{document}
\pagestyle{empty}
\maketitle
\newpage

\pagestyle{fancy}
\fancyhead[LO,LE]{qvw203 - nkh877 - }
\fancyhead[RO, RE]{Assignment 1}

\section{I.3.1}
Running the algorithms for various k's, we get the following accuracies:

\begin{itemize}
\item[-] k = 1; 0.815789473684\%
\item[-] k = 3; 0.710526315789\% 
\item[-] k = 5; 0.736842105263\%
\end{itemize}

As such, k = 1 is clearly the best k for this training- and test set.

\end{document}
